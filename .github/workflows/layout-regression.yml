name: Layout Refinement Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
    paths:
      - 'src/core/layout/**'
      - 'src/core/services/metrics/**'
      - 'src/core/services/comparison/**'
      - 'src/apps/embedded/services/refinement/**'
      - 'tests/refinement/**'
      - 'tests/metrics/**'
      - 'package.json'

  # Allow manual trigger
  workflow_dispatch:
    inputs:
      update_baselines:
        description: 'Update baselines after run'
        required: false
        default: false
        type: boolean
      strict_mode:
        description: 'Fail on moderate regressions'
        required: false
        default: false
        type: boolean

jobs:
  # Ladle-based refinement tests with parallel execution
  ladle-refinement-tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        shard: [1, 2, 3, 4]  # Parallel execution across 4 shards
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Cache Playwright browsers
        uses: actions/cache@v3
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ hashFiles('package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-playwright-

      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: Run Ladle-based refinement tests (shard ${{ matrix.shard }}/4)
        run: npm run test:refinement:ladle -- --shard=${{ matrix.shard }}/4

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: refinement-results-ladle-shard-${{ matrix.shard }}
          path: test-results/refinement/
          retention-days: 30

      - name: Upload metrics
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: metrics-ladle-shard-${{ matrix.shard }}
          path: test-results/metrics/
          retention-days: 30

  # Legacy embedded app tests (during transition)
  legacy-refinement-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Cache Playwright browsers
        uses: actions/cache@v3
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ hashFiles('package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-playwright-

      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: Run legacy refinement tests
        run: npm run test:refinement:legacy

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: refinement-results-legacy
          path: test-results/refinement/
          retention-days: 30

  regression-check:
    runs-on: ubuntu-latest
    needs: [ladle-refinement-tests, legacy-refinement-tests]
    if: always()
    permissions:
      contents: read
      pull-requests: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Cache Playwright browsers
        uses: actions/cache@v3
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ hashFiles('package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-playwright-

      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: Download baseline artifacts
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: layout-regression.yml
          name: quality-baselines
          path: test-results/baselines
          if_no_artifact_found: warn
        continue-on-error: true

      - name: Run metrics report
        run: npm run metrics:report
        continue-on-error: true

      - name: Run regression check
        id: regression
        run: |
          if [ "${{ github.event.inputs.strict_mode }}" = "true" ]; then
            export STRICT_REGRESSION=true
          fi
          npm run metrics:regression-check 2>&1 | tee regression-output.txt
          echo "exit_code=${PIPESTATUS[0]}" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: Generate summary
        id: summary
        run: |
          # Read regression report if exists
          if [ -f test-results/metrics/regression-report.json ]; then
            TOTAL=$(jq '.summary.total' test-results/metrics/regression-report.json)
            PASSED=$(jq '.summary.passed' test-results/metrics/regression-report.json)
            FAILED=$(jq '.summary.failed' test-results/metrics/regression-report.json)
            SEVERE=$(jq '.summary.severe' test-results/metrics/regression-report.json)
            MODERATE=$(jq '.summary.moderate' test-results/metrics/regression-report.json)
            MINOR=$(jq '.summary.minor' test-results/metrics/regression-report.json)

            echo "total=$TOTAL" >> $GITHUB_OUTPUT
            echo "passed=$PASSED" >> $GITHUB_OUTPUT
            echo "failed=$FAILED" >> $GITHUB_OUTPUT
            echo "severe=$SEVERE" >> $GITHUB_OUTPUT
            echo "moderate=$MODERATE" >> $GITHUB_OUTPUT
            echo "minor=$MINOR" >> $GITHUB_OUTPUT
          else
            echo "total=0" >> $GITHUB_OUTPUT
            echo "passed=0" >> $GITHUB_OUTPUT
            echo "failed=0" >> $GITHUB_OUTPUT
            echo "severe=0" >> $GITHUB_OUTPUT
            echo "moderate=0" >> $GITHUB_OUTPUT
            echo "minor=0" >> $GITHUB_OUTPUT
          fi

      - name: Create PR comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            // Read summary data
            const total = '${{ steps.summary.outputs.total }}';
            const passed = '${{ steps.summary.outputs.passed }}';
            const failed = '${{ steps.summary.outputs.failed }}';
            const severe = '${{ steps.summary.outputs.severe }}';
            const moderate = '${{ steps.summary.outputs.moderate }}';
            const minor = '${{ steps.summary.outputs.minor }}';
            const exitCode = '${{ steps.regression.outputs.exit_code }}';

            // Determine overall status
            let statusEmoji = '✅';
            let statusText = 'All checks passed';
            if (failed > 0) {
              statusEmoji = '❌';
              statusText = `${failed} regression(s) detected`;
            } else if (minor > 0 || moderate > 0) {
              statusEmoji = '⚠️';
              statusText = 'Minor regressions detected (not blocking)';
            }

            // Build comment body
            let body = `## ${statusEmoji} Layout Quality Regression Check\n\n`;
            body += `**Status:** ${statusText}\n\n`;
            body += `### Summary\n`;
            body += `| Metric | Count |\n`;
            body += `|--------|-------|\n`;
            body += `| Total Checks | ${total} |\n`;
            body += `| Passed | ${passed} |\n`;
            body += `| Failed | ${failed} |\n`;
            body += `| Severe Regressions | ${severe} |\n`;
            body += `| Moderate Regressions | ${moderate} |\n`;
            body += `| Minor Regressions | ${minor} |\n`;
            body += `\n`;

            // Add details if there are issues
            if (parseInt(failed) > 0 || parseInt(severe) > 0) {
              body += `### ⚠️ Action Required\n`;
              body += `Severe regressions were detected in layout quality metrics. `;
              body += `Please review the changes and ensure they don't negatively impact diagram readability.\n\n`;
              body += `**To investigate:**\n`;
              body += `1. Run \`npm run metrics:regression-check\` locally\n`;
              body += `2. Review the regression report in \`test-results/metrics/regression-report.json\`\n`;
              body += `3. If changes are intentional, update baselines with \`npm run metrics:update-baselines\`\n\n`;
            }

            // Add threshold info
            body += `### Thresholds\n`;
            body += `- Minor: < 5% decrease\n`;
            body += `- Moderate: 5-10% decrease\n`;
            body += `- Severe: > 10% decrease (blocks PR)\n`;
            body += `- Quality Floor: 0.5 minimum score\n\n`;

            body += `---\n`;
            body += `*Generated by Layout Quality Regression Check workflow*`;

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('Layout Quality Regression Check')
            );

            if (botComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }

      - name: Upload test artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: regression-artifacts
          path: |
            test-results/metrics/
            test-results/refinement/
            playwright-report/
          retention-days: 30

      - name: Upload baselines (if updating)
        if: github.event.inputs.update_baselines == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: quality-baselines
          path: test-results/baselines/
          retention-days: 90

      - name: Check for failures
        if: steps.regression.outputs.exit_code != '0'
        run: |
          echo "::error::Layout quality regression check failed"
          echo "See the regression report for details"
          exit 1

  # Optional: Update baselines on main branch
  update-baselines:
    runs-on: ubuntu-latest
    needs: regression-check
    if: |
      github.event_name == 'push' &&
      github.ref == 'refs/heads/main' &&
      needs.regression-check.result == 'success'

    permissions:
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: Update baselines
        run: npm run metrics:update-baselines

      - name: Upload new baselines
        uses: actions/upload-artifact@v4
        with:
          name: quality-baselines
          path: test-results/baselines/
          retention-days: 90
